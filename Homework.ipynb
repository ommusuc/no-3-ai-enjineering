{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 課題の概要\n",
        "\n",
        "この宿題では、講義で学んだRAG(Retrieval-Augmented Generation)技術を用いて、LLMの生成\n",
        "内容を改善する実践的な取り組みを行います。演習で利用したコードをベースに、独自の質問と参照文書を用\n",
        "いて実験を行い、RAGの効果を定量的・定性的に評価します。\n",
        "この宿題を通じて、「テストデータの作成」と「改善のプロセス」について理解を深め、実際のアプリケーション開発\n",
        "に役立てることを目指します。\n",
        "\n"
      ],
      "metadata": {
        "id": "vrOVSydXC8n3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 内容\n",
        "\n",
        "宿題の内容\n",
        "1. 独自の質問と参照資料の作成\n",
        "- 自分で5つ以上の質問文を考案してください\n",
        "- 各質問に対する回答を含む参照文書を用意してください\n",
        "- 少なくとも1つは、LLMが単体では正確に答えられないような知識を含む質問にしてください\n",
        "2. 実験の実施\n",
        "- 演習で使用したコードをベースに、以下の2つの方法で回答を生成してください\n",
        "  - ベースのLLM(RAGなし)での回答生成\n",
        "  -  RAGを組み合わせた回答生成\n",
        "- 回答の評価では、単純なYes/No判定でも良いです\n",
        "  - より詳細な評価指標も検討していただけるとなお良いです\n",
        "\n",
        "3. 結果分析と考察\n",
        "\n",
        "- 生成した結果をまとめ、RAGありとRAGなしの差異を分析してください\n",
        "- RAGによって回答が改善したケースと悪化したケースの両方について考察してください- 結果に基づいて、RAGの有効性と限界についての考察を記述してください"
      ],
      "metadata": {
        "id": "rNgYrKtoDbVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 扱う条件\n",
        "\n",
        "1. 使用するモデル\n",
        "\n",
        "2024年4月リリースのMeta-Llama-3-8B-Instructを使用する\n",
        "\n",
        "\n",
        "2. 参考文献\n",
        "\n",
        "・ディズニー公式\n",
        "\n",
        "・Wikipedia\n",
        "\n",
        "・[映画『インサイド・ヘッド』あらすじ&ネタバレ！キャラクター、声優キャスト、トリビアも♪\n",
        "](https://castel.jp/p/4118)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q-64Q-bNNzw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 質問概要\n",
        "\n",
        "\n",
        "・ディズニーに関する質問\n",
        "\n",
        "\n",
        "1. アナと雪の女王」に登場する、魔法で作られた雪だるまの名前はなに？\n",
        "\n",
        "  解答：オラフ\n",
        "\n",
        "2. 「アナと雪の女王」でエピソードが展開される国の名前は何ですか？\n",
        "\n",
        "  解答：アレンデール\n",
        "\n",
        "\n",
        "\n",
        "3. ディズニー映画「インサイドヘッド」に関して教えて\n",
        "\n",
        "  期待する解答：\n",
        "\n",
        "  主人公少女ライリーの頭の中にいるヨロコビ、カナシミ、イカリ、ムカムカ、ビビリ5つの感情が繰り広げる冒険と1人の少女の成長を描いたストーリー\n",
        "\n",
        "4. ディズニー映画「インサイドヘッド」で現在までに登場している感情のキャラクターを教えて\n",
        "\n",
        "  解答：\n",
        "  \n",
        "  ヨロコビ、カナシミ、イカリ、ムカムカ、ビビリ\n",
        "\n",
        "  シンパイ、イイナ、ハズカシ、ダリィ\n",
        "\n",
        "5. ディズニーとピクサーの違いを教えて\n",
        "\n",
        "  解答の評価ポイント：\n",
        "\n",
        "  設立年\n",
        "\n",
        "  共通する点\n",
        "\n",
        "  例)\n",
        "\n",
        "  親会社が、ウォルトディズニーカンパニーであることなど\n",
        "\n",
        "  異なる点\n",
        "\n",
        "  例)\n",
        "\n",
        "  名前・コンセプトなど\n",
        "\n",
        "  この二つが明確にわけられているかどうかを判断基準として定性的に評価する}"
      ],
      "metadata": {
        "id": "SF6z5scSE4Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote add origin https://github.com/ommusuc/no-4-ai-enjineering.git\n",
        "!git branch -M main\n",
        "!git push -u origin main"
      ],
      "metadata": {
        "id": "No6G9nKfxOQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzDUjLaAC6LY"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip install google-colab-selenium\n",
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HuggingFace Login\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "JLZW0XeSI5aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDAが利用可能ならGPUを、それ以外ならCPUをデバイスとして設定\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "7KQOSTo3I8vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル(Llama3)の読み込み\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            device_map=\"auto\",\n",
        "            quantization_config=bnb_config,\n",
        "            torch_dtype=torch.bfloat16,\n",
        "        )"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yD_BM9bzI9OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_output(query, system_prompt=None):\n",
        "  if system_prompt is None:\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": query},\n",
        "    ]\n",
        "  else:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": query},\n",
        "    ]\n",
        "  input_ids = tokenizer.apply_chat_template(\n",
        "      messages,\n",
        "      add_generation_prompt=True,\n",
        "      return_tensors=\"pt\"\n",
        "  ).to(model.device)\n",
        "\n",
        "  terminators = [\n",
        "      tokenizer.eos_token_id,\n",
        "      tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "  ]\n",
        "\n",
        "  outputs = model.generate(\n",
        "      input_ids,\n",
        "      max_new_tokens=400,\n",
        "      eos_token_id=terminators,\n",
        "      do_sample=False,\n",
        "      # temperature=0.6, # If do_sample=True\n",
        "      # top_p=0.9,  # If do_sample=True\n",
        "  )\n",
        "\n",
        "  response = outputs[0][input_ids.shape[-1]:]\n",
        "  return tokenizer.decode(response, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "fh2xpMSzJB4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1～5に関して質問を行う\n"
      ],
      "metadata": {
        "id": "9sdwVasDanV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 アナと雪の女王」に登場する、魔法で作られた雪だるまの名前はなに？"
      ],
      "metadata": {
        "id": "WWgofRljbC_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"質問に回答してください。必ず「日本語で回答」すること。\"\n",
        "question =  \"アナと雪の女王」に登場する、魔法で作られた雪だるまの名前はなに？\"\n",
        "response = generate_output(question, system_prompt)"
      ],
      "metadata": {
        "id": "VbUcoEUgJGP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "JxRnR5s5JJtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 「アナと雪の女王」でエピソードが展開される国の名前は何ですか？"
      ],
      "metadata": {
        "id": "8_7sKaADbFDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"質問に回答してください。必ず「日本語で回答」すること。\"\n",
        "question =  \"「アナと雪の女王」でエピソードが展開される国の名前は何ですか？\"\n",
        "response = generate_output(question, system_prompt)"
      ],
      "metadata": {
        "id": "UYsKNvVgLxm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "pY45MymfbeQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.ディズニー映画「インサイドヘッド」に関して教えて"
      ],
      "metadata": {
        "id": "L1nM558Ebj-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"質問に回答してください。必ず「日本語で回答」すること。\"\n",
        "question =  \"ディズニー映画「インサイドヘッド」に関して教えて\"\n",
        "response = generate_output(question, system_prompt)"
      ],
      "metadata": {
        "id": "UMYzMW2qbgaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "4gVlVHANbqk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.ディズニー映画「インサイドヘッド」で現在までに登場している感情のキャラクターを教えて"
      ],
      "metadata": {
        "id": "2LelBfwhbv2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"質問に回答してください。必ず「日本語で回答」すること。\"\n",
        "question =  \"ディズニー映画「インサイドヘッド」で現在までに登場している感情のキャラクターを教えて\"\n",
        "response = generate_output(question, system_prompt)"
      ],
      "metadata": {
        "id": "DTAWwX97bsij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "mmRuXVaHcNs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 ディズニーとピクサーの違いを教えて"
      ],
      "metadata": {
        "id": "5mBAPq-0cS3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_output2(query, system_prompt=None):\n",
        "  if system_prompt is None:\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": query},\n",
        "    ]\n",
        "  else:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": query},\n",
        "    ]\n",
        "  input_ids = tokenizer.apply_chat_template(\n",
        "      messages,\n",
        "      add_generation_prompt=True,\n",
        "      return_tensors=\"pt\"\n",
        "  ).to(model.device)\n",
        "\n",
        "  terminators = [\n",
        "      tokenizer.eos_token_id,\n",
        "      tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "  ]\n",
        "\n",
        "  outputs = model.generate(\n",
        "      input_ids,\n",
        "      max_new_tokens=2000,\n",
        "      eos_token_id=terminators,\n",
        "      do_sample=False,\n",
        "      # temperature=0.6, # If do_sample=True\n",
        "      # top_p=0.9,  # If do_sample=True\n",
        "  )\n",
        "\n",
        "  response = outputs[0][input_ids.shape[-1]:]\n",
        "  return tokenizer.decode(response, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "5h8MawdPc4DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"質問に回答してください。必ず「日本語で回答」すること。\"\n",
        "question =  \"ディズニーとピクサーの違いを教えて\"\n",
        "response = generate_output(question, system_prompt)"
      ],
      "metadata": {
        "id": "_OjT22plcRiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "ayHp1hpVcqnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oY7xap1Ycr_3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}